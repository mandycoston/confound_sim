---
title: "Low Dim Linear Models"
output: html_notebook
---

This is a work in progress. Work paused since I think it's more compelling to work in high-dimensional setting
This notebook is for low dim linear models with interaction terms.
```{r}
library(tidyverse)
library(glmnet)
source("utils.R")
```
z1 z2 z3 v1 v2 v3 v1v2 v1v3 v2v3

```{r}
set.seed(2)
results <- tibble()
n <- 4 * 1000
n_sim <- 100
d <- 6
for (sim_num in c(1:n_sim)) {
    q <- round(d/2) # dimension of hidden confounder z
    p <- d - q # dimension of v
    s <- sort(rep(1:4, n / 4))
    x <- matrix(rnorm(n * d), n, d)
    x <- as.data.frame(x)
    colnames(x) <- c("z1", "z2", "z3", "v1", "v2", "v3")
    x %>%
      dplyr::mutate(v1v2 = v1*v2,
                    v1v3 = v1 *v3,
                    v2v3 = v2*v3) -> x
    x %>% 
      dplyr::select(-z1, -z2, -z3) -> v
    x %>% 
      dplyr::mutate(mu0 = z1 + z2 + z3 + v1 + v2 + v3 + v1v2 + v1v3 + v2v3,
                    nu = v1 + v2 + v3 + v1v2 + v1v3 + v2v3,
                    prop =  sigmoid(z1 + z2 + z3 + v1 + v2 +  v1v2  + 0.3
                      )/1.05
                    a = rbinom(n,1, prop)) -> df
    summary(df)
     prop <- sigmoid(as.numeric(x %*% rep(c(1, 0), c(alpha, d - alpha))) / sqrt(4 * alpha))
    a <- rbinom(n, 1, prop)
    y0 <- mu0 + rnorm(n, sd = sqrt(sum(mu0^2) / (n * 2)))

    # propvhat <- as.numeric(predict(cv.glmnet(v, a, subset = (s = 1), famliy = "binomial"), newx = v, type = "response", s = "lambda.min"))

    # stage 1
    prop_model <- glm(a ~ ., data = xdf, subset = (s == 1), family = "binomial")
    prophat <- as.numeric(predict(prop_model, newdata = xdf, type = "response"))
    
    mu_model <- lm(y0 ~ ., data = xdf, subset = (s == 2 & a == 0))
    muhat <- as.numeric(predict(mu_model, newdata = xdf))
    
    bchat <- (1 - a) * (y0 - muhat) / (1 - prophat) + muhat
    bc_true <- (1 - a) * (y0 - mu0) / (1 - prop) + mu0

    # stage 2
    conf_model <- lm(y0 ~ ., data = vdf, subset = ((s == 3) & (a == 0)))
    conf <- predict(conf_model, newdata = vdf)

    pl_model <- lm(muhat ~ ., data = vdf, subset = (s == 3))
    pl <- predict(pl_model, newdata = vdf)

    bc_model <- lm(bchat ~ ., data = vdf, subset = (s == 3))
    bc <- predict(bc_model, newdata = vdf)

    bct_model <- lm(bc_true ~ ., data = vdf, subset = (s == 3))
    bct <- predict(bct_model, newdata = vdf)
    
    results <- rbind(results, tibble(
      "mse" = c(
        mean((conf - nu)[s == 4]^2),
        mean((pl - nu)[s == 4]^2),
        mean((bc - nu)[s == 4]^2),
        mean((bct - nu)[s == 4]^2)
      ),
      "method" = c("conf", "pl", "bc", "bct"),
      "dim" = d,
      "sim" = sim_num
    ))
  }


```


```{r}
results %>%
  dplyr::group_by(dim, method) %>%
  dplyr::summarise(mmse = mean(mse),
                   low = mean(mse) - 1.96*sqrt(var(mse)/n()),
                   high = mean(mse) + 1.96*sqrt(var(mse)/n()),
                   ) %>%
  ggplot(aes(x = method, y = mmse, color = method)) +geom_point() + geom_errorbar(aes(ymin = low, ymax = high))  + facet_grid(dim~., scales = "free_y")
```

```{r}
results %>%
  dplyr::group_by(dim, method) %>%
  dplyr::summarise(mmse = mean(mse),
                   low = mean(mse) - 1.96*sqrt(var(mse)/n()),
                   high = mean(mse) + 1.96*sqrt(var(mse)/n()),
                   ) %>%
  filter(method %in% c("all_lasso", "conf_lasso")) %>%
  ggplot(aes(x = method, y = mmse, color = method)) +geom_point() + geom_errorbar(aes(ymin = low, ymax = high))  + facet_grid(dim~., scales = "free_y")
```
